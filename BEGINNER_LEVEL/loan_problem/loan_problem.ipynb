{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
       "1   Male     Yes          1      Graduate            No             4583   \n",
       "2   Male     Yes          0      Graduate           Yes             3000   \n",
       "3   Male     Yes          0  Not Graduate            No             2583   \n",
       "4   Male      No          0      Graduate            No             6000   \n",
       "5   Male     Yes          2      Graduate           Yes             5417   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "1             1508.0       128.0             360.0             1.0   \n",
       "2                0.0        66.0             360.0             1.0   \n",
       "3             2358.0       120.0             360.0             1.0   \n",
       "4                0.0       141.0             360.0             1.0   \n",
       "5             4196.0       267.0             360.0             1.0   \n",
       "\n",
       "  Property_Area Loan_Status  \n",
       "1         Rural           N  \n",
       "2         Urban           Y  \n",
       "3         Urban           Y  \n",
       "4         Urban           Y  \n",
       "5         Urban           Y  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../hand_made_stuff')\n",
    "from handmadestuff import fit_predict_report\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "# Importing data\n",
    "loan_df = pd.read_csv('data/loan.csv')\n",
    "\n",
    "# Dropping rows containing NaN values\n",
    "loan_df = loan_df.dropna().iloc[:, 1:]\n",
    "\n",
    "# Display how the data looks\n",
    "loan_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the source and the target values\n",
    "X = loan_df.iloc[:, :11].values\n",
    "y = loan_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Encoding the source values\n",
    "labelencoder_X = LabelEncoder()\n",
    "categorical_sources = [0, 1, 2, 3, 4, 10]\n",
    "for i in categorical_sources:\n",
    "    X[:, i] = labelencoder_X.fit_transform(X[:, i])\n",
    "    \n",
    "# Encoding the target values (N, Y => 0, 1)\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the source values into the categorical and the continuous variables\n",
    "X_1 = X[:, categorical_sources]\n",
    "X_2 = X[:, [item for item in list(range(len(X[0]))) if item not in categorical_sources]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot encoding the categorical values\n",
    "\n",
    "# X_1 is a numpy array, which shape is (480, 6).\n",
    "# Second and fifth columns are the only that, contain values higher than 1\n",
    "onehotencoder = OneHotEncoder()\n",
    "X_1_encoded = onehotencoder.fit_transform(X_1[:, [2, 5]]).toarray()[:, 1:6]\n",
    "\n",
    "# Columns [0, 1, 3, 4] contain only 0 and 1 values, thus not needed to be hot encoded\n",
    "X_1_not_encoded = X_1[:, [0, 1, 3, 4]]\n",
    "\n",
    "# Concatenating X_1_encoded with X_1_not_encoded to obtain X_1 with hot encoded values\n",
    "X_1 = np.concatenate((X_1_not_encoded, X_1_encoded), axis = 1).astype('int')\n",
    "# Concatenating X_1 and X_2 to obtain X\n",
    "X = np.concatenate((X_1, X_2.astype(int)), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the variables' significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for model optimization (with p-values only)\n",
    "def backward_elimination_p(x, y, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            x = np.delete(x, list(regressor_OLS.pvalues).index(maxVar), 1)\n",
    "    print(regressor_OLS.summary())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function for model optimization (with p-values and Adjusted R Squared)\n",
    "import statsmodels.formula.api as sm\n",
    "def backward_elimination_p_r(x, y, SL):\n",
    "    numVars = len(x[0])\n",
    "    temp = np.zeros(x.shape).astype(int)\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        adjR_before = regressor_OLS.rsquared_adj.astype(float)\n",
    "        if maxVar > SL:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    temp[:,j] = x[:, j]\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    tmp_regressor = sm.OLS(y, x).fit()\n",
    "                    adjR_after = tmp_regressor.rsquared_adj.astype(float)\n",
    "                    if (adjR_before >= adjR_after):\n",
    "                        x_rollback = np.hstack((x, temp[:,[0,j]]))\n",
    "                        x_rollback = np.delete(x_rollback, j, 1)\n",
    "                        print (regressor_OLS.summary())\n",
    "                        return x_rollback\n",
    "                    else:\n",
    "                        continue\n",
    "    regressor_OLS.summary()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.322\n",
      "Model:                            OLS   Adj. R-squared:                  0.302\n",
      "Method:                 Least Squares   F-statistic:                     15.81\n",
      "Date:                Wed, 14 Nov 2018   Prob (F-statistic):           1.40e-31\n",
      "Time:                        23:38:33   Log-Likelihood:                -216.80\n",
      "No. Observations:                 480   AIC:                             463.6\n",
      "Df Residuals:                     465   BIC:                             526.2\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1120      0.121      0.928      0.354      -0.125       0.349\n",
      "x1             0.0544      0.050      1.079      0.281      -0.045       0.154\n",
      "x2             0.0899      0.043      2.085      0.038       0.005       0.175\n",
      "x3            -0.0623      0.045     -1.373      0.170      -0.151       0.027\n",
      "x4            -0.0154      0.052     -0.294      0.769      -0.118       0.087\n",
      "x5            -0.0550      0.052     -1.055      0.292      -0.157       0.047\n",
      "x6             0.0326      0.052      0.630      0.529      -0.069       0.134\n",
      "x7             0.0224      0.069      0.327      0.744      -0.112       0.157\n",
      "x8            -0.0309      0.047     -0.661      0.509      -0.123       0.061\n",
      "x9             0.1133      0.043      2.649      0.008       0.029       0.197\n",
      "x10         6.856e-07   3.77e-06      0.182      0.856   -6.73e-06     8.1e-06\n",
      "x11        -8.989e-06   7.19e-06     -1.251      0.212   -2.31e-05    5.13e-06\n",
      "x12           -0.0004      0.000     -1.518      0.130      -0.001       0.000\n",
      "x13           -0.0001      0.000     -0.491      0.623      -0.001       0.000\n",
      "x14            0.6718      0.050     13.332      0.000       0.573       0.771\n",
      "==============================================================================\n",
      "Omnibus:                       67.357   Durbin-Watson:                   1.835\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               92.942\n",
      "Skew:                          -1.060   Prob(JB):                     6.57e-21\n",
      "Kurtosis:                       3.392   Cond. No.                     5.53e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.53e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Displaying the significance of all variables\n",
    "X = np.append(np.ones((X.shape[0], 1)), X, axis = 1)\n",
    "regressor_OLS = sm.OLS(y, X).fit()\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.786\n",
      "Model:                            OLS   Adj. R-squared:                  0.785\n",
      "Method:                 Least Squares   F-statistic:                     584.7\n",
      "Date:                Wed, 14 Nov 2018   Prob (F-statistic):          2.47e-159\n",
      "Time:                        23:38:37   Log-Likelihood:                -222.35\n",
      "No. Observations:                 480   AIC:                             450.7\n",
      "Df Residuals:                     477   BIC:                             463.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0928      0.033      2.784      0.006       0.027       0.158\n",
      "x2             0.1232      0.035      3.515      0.000       0.054       0.192\n",
      "x3             0.6818      0.031     21.940      0.000       0.621       0.743\n",
      "==============================================================================\n",
      "Omnibus:                       72.125   Durbin-Watson:                   1.881\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              102.094\n",
      "Skew:                          -1.113   Prob(JB):                     6.77e-23\n",
      "Kurtosis:                       3.391   Cond. No.                         2.92\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Elimintaing non significant sources (evaluating only by p-values). \n",
    "# Reducing the amount of the source values\n",
    "SL = 0.05\n",
    "X_opt = X\n",
    "X_modeled_p = backward_elimination_p(X_opt, y, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.790\n",
      "Model:                            OLS   Adj. R-squared:                  0.787\n",
      "Method:                 Least Squares   F-statistic:                     222.3\n",
      "Date:                Wed, 14 Nov 2018   Prob (F-statistic):          9.19e-155\n",
      "Time:                        23:38:39   Log-Likelihood:                -217.76\n",
      "No. Observations:                 480   AIC:                             451.5\n",
      "Df Residuals:                     472   BIC:                             484.9\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0750      0.045      1.667      0.096      -0.013       0.163\n",
      "x2             0.1033      0.040      2.568      0.011       0.024       0.182\n",
      "x3            -0.0555      0.044     -1.274      0.203      -0.141       0.030\n",
      "x4            -0.0582      0.048     -1.219      0.224      -0.152       0.036\n",
      "x5             0.1330      0.035      3.779      0.000       0.064       0.202\n",
      "x6         -9.313e-06   6.91e-06     -1.347      0.179   -2.29e-05    4.27e-06\n",
      "x7            -0.0003      0.000     -1.637      0.102      -0.001    6.82e-05\n",
      "x8             0.6930      0.039     17.585      0.000       0.616       0.770\n",
      "==============================================================================\n",
      "Omnibus:                       68.685   Durbin-Watson:                   1.841\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               95.108\n",
      "Skew:                          -1.065   Prob(JB):                     2.23e-21\n",
      "Kurtosis:                       3.468   Cond. No.                     9.49e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 9.49e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Elimintaing non significant sources (evaluating by p-values and Adjusted R Squared). \n",
    "# Reducing the amount of the source values\n",
    "X_modeled_p_r = backward_elimination_p_r(X_opt, y, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adj. R-squared (only p-values method) == 0.785\n",
    "# Adj. R-squared (p-values and Adjusted R Squared method) == 0.787\n",
    "# \n",
    "# Not a significatn difference, so I'll choose the model with fewer variables, \n",
    "# therefore I choose X_modeled_p for the source values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the train and the test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_modeled_p, y, test_size = 0.2,\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Scaling the data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xb604eb8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.scatter(X_modeled_p[:, 0], X_modeled_p[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models and predicting test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificator used:\n",
      " knn\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[19 16]\n",
      " [11 50]] \n",
      "\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.54      0.58        35\n",
      "          1       0.76      0.82      0.79        61\n",
      "\n",
      "avg / total       0.71      0.72      0.71        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_predict_report(loan_df, 'knn', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificator used:\n",
      " svc\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[13 22]\n",
      " [ 0 61]] \n",
      "\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        35\n",
      "          1       0.73      1.00      0.85        61\n",
      "\n",
      "avg / total       0.83      0.77      0.74        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_predict_report(loan_df, 'svc', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificator used:\n",
      " lr\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[13 22]\n",
      " [ 0 61]] \n",
      "\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        35\n",
      "          1       0.73      1.00      0.85        61\n",
      "\n",
      "avg / total       0.83      0.77      0.74        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_predict_report(loan_df, 'lr', X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
