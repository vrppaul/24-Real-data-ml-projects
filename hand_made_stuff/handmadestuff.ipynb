{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which calculates euclidean distance between two data points\n",
    "def euclidian_distance(point1, point2):\n",
    "    \"\"\"This is a nand-made function for calculating Euclidian Distance.\n",
    "    Made for learning purposes.\"\"\"\n",
    "    \n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError('Points should have the same number of dimensions.')\n",
    "    \n",
    "    distance = 0\n",
    "    dims = len(point1)\n",
    "    \n",
    "    for i in range(dims):\n",
    "        distance += np.square(point1[i] - point2[i])\n",
    "        \n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hand-made KNN class\n",
    "class HandMadeKNN:\n",
    "    \"\"\"This is a toy hand-made class made for learning purposes.\n",
    "    It's only goal is to classify and label the data put into it.\n",
    "    \n",
    "    'brute' is the only method available at the moment\"\"\"\n",
    "    \n",
    "    def __init__(self, X_train = None, y_train = None, k = None):\n",
    "        \"\"\"Method to declare all the needed inputs without using '.fit' method\"\"\"\n",
    "        self.fit(X_train, y_train, k)\n",
    "        \n",
    "    def fit(self, X_train, y_train, k = 1):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.k = k\n",
    "        \n",
    "    def predict(self, to_predict = None):\n",
    "        \"\"\"Method for predicting the class of input data (only 'brute')\"\"\"\n",
    "        \n",
    "        prevailing_classes = []\n",
    "        \n",
    "        if isinstance(to_predict, pd.core.frame.DataFrame):\n",
    "            length = list(to_predict.index)\n",
    "        elif isinstance(to_predict[0], list) or isinstance(to_predict[0], np.ndarray):\n",
    "            length = range(len(to_predict))\n",
    "        else:\n",
    "            length = [0]\n",
    "        \n",
    "        for i in length:\n",
    "            # Calculating distances to any point\n",
    "            distances = self._calculate_distances(to_predict, i)\n",
    "            sorted_distances = self._sort_distances(distances)\n",
    "\n",
    "            # Slicing the array of all distances to leave just k-nearest-neighbors\n",
    "            sorted_distances = sorted_distances[0:self.k]\n",
    "\n",
    "            # Defining the prevailing class\n",
    "            prevailing_class = self._define_class(sorted_distances)\n",
    "            prevailing_classes.append(prevailing_class)\n",
    "        \n",
    "        return prevailing_classes\n",
    "    \n",
    "    def _calculate_distances(self, to_predict, index = None):\n",
    "        \"\"\"Calculating distances from training and test datapoints\"\"\"\n",
    "        \n",
    "        distances = {}\n",
    "        \n",
    "        if isinstance(to_predict, pd.core.frame.DataFrame):\n",
    "            to_predict = to_predict.loc[index]\n",
    "        elif isinstance(to_predict[0], list) or isinstance(to_predict[0], np.ndarray):\n",
    "            to_predict = to_predict[index]\n",
    "    \n",
    "        for i in list(self.X_train.index):\n",
    "\n",
    "            dist = euclidian_distance(self.X_train.loc[i], to_predict)\n",
    "\n",
    "            distances[i] = dist\n",
    "            \n",
    "        return distances\n",
    "    \n",
    "    def _sort_distances(self, dict_of_distances):\n",
    "        \"\"\"Sorts the dict of distances in descending order, \n",
    "        unpacks the resulted list of tuples and returns a list of sorted indexes\"\"\"\n",
    "        \n",
    "        sorted_distances = sorted(dict_of_distances.items(), key=lambda kv: kv[1])\n",
    "        \n",
    "        for i in range(len(sorted_distances)):\n",
    "            sorted_distances[i] = sorted_distances[i][0]\n",
    "        \n",
    "        return sorted_distances\n",
    "    \n",
    "    def _define_class(self, sorted_distances):\n",
    "        \"\"\"Defining the prevailng class of nearest neighbors\"\"\"\n",
    "        \n",
    "        prevailng_class = (self.y_train[sorted_distances]\n",
    "                            .value_counts()\n",
    "                            .index\n",
    "                            .values[0])\n",
    "        \n",
    "        return prevailng_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_made_cm(y_pred, y_actual):\n",
    "    \"\"\"Hand-made confusion matrix, \n",
    "    which recieves two parametres as input: predicted classes and real classes\n",
    "    and which returns a matrix of number in a form\n",
    "    \n",
    "    \\t\\t\\tpredicted values\n",
    "    actual values\"\"\"\n",
    "    \n",
    "    if isinstance(y_pred, pd.core.series.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if isinstance(y_actual, pd.core.series.Series):\n",
    "        y_actual = y_actual.values\n",
    "    \n",
    "    if len(y_pred) != len(y_actual):\n",
    "        raise ValueError('Amount of predicted and actual values have to be the same (len(y_pred) == len(y_actual))')\n",
    "        \n",
    "    n_classes = sorted(set(y_pred).union(set(y_actual)))\n",
    "    size = len(sorted(set(y_pred).union(set(y_actual))))\n",
    "    cm_matrix = np.zeros((size, size))\n",
    "    \n",
    "    arr_length = range(len(y_pred))\n",
    "    \n",
    "    for i in arr_length:\n",
    "        if y_actual[i] == y_pred[i]:\n",
    "            index = list(n_classes).index(y_actual[i])\n",
    "            cm_matrix[index][index] += 1\n",
    "        else:\n",
    "            actual_index = list(n_classes).index(y_actual[i])\n",
    "            predicted_index = list(n_classes).index(y_pred[i])\n",
    "            cm_matrix[predicted_index][actual_index] += 1\n",
    "    \n",
    "    return(cm_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def hand_made_train_test_split(X_values, y_values = None, test_size = 0.2):\n",
    "    \"\"\"Hand-made function, which splits data into train and test sets\n",
    "    with a given or default percent of test samples\"\"\"\n",
    "    \n",
    "    set_of_indexes = set(range(len(X_values)))\n",
    "    \n",
    "    test_indexes = sorted(random.sample(range(len(X_values)), int(len(X_values) * test_size)))\n",
    "    training_indexes = list(set_of_indexes.difference(set(test_indexes)))\n",
    "    \n",
    "    if y_values is None:\n",
    "        return [X_values.iloc[training_indexes], X_values.iloc[test_indexes]]\n",
    "    else:\n",
    "         return [X_values.iloc[training_indexes], X_values.iloc[test_indexes],\n",
    "                 y_values.iloc[training_indexes], y_values.iloc[test_indexes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_efficiency(cm):\n",
    "    \"\"\"Function which calculates efficiency of the given confusion matrix\"\"\"\n",
    "    \n",
    "    sum_total = 0\n",
    "    sum_predicted = 0\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        sum_total += sum(cm[i])\n",
    "        sum_predicted += cm[i][i]\n",
    "        \n",
    "    return sum_predicted / sum_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_classifier(classifier, X_train, y_train):\n",
    "    \"\"\"Function that contains all steps of the code which visualises the classifier's results\"\"\"\n",
    "    \n",
    "    from matplotlib.colors import ListedColormap\n",
    "    X_set, y_set = X_train, y_train\n",
    "    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                         np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "    \n",
    "    plt.figure(figsize = (10,10)) \n",
    "    plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "                 alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n",
    "    plt.xlim(X1.min(), X1.max())\n",
    "    plt.ylim(X2.min(), X2.max())\n",
    "    for i, j in enumerate(np.unique(y_set)):\n",
    "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                    c = ListedColormap(('red', 'green', 'blue'))(i),\n",
    "                    label = iris.target_names[int(j)], s = 50)\n",
    "    plt.xlabel('\\nPrincipal Component 1', fontsize = 15)\n",
    "    plt.ylabel('Principal Component 2', fontsize = 15)\n",
    "    plt.title('\\n2 component PCA\\n', fontsize = 20)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_report(classifier_name, X_train, y_train, X_test, y_test, \n",
    "                       n_neighbors = 5, svc_kernel = 'rbf', svc_c = 1,\n",
    "                      visualise = False):\n",
    "    \"\"\"Function that calculates precision of the chosen classifier\n",
    "    \n",
    "    If visualise == True, a plot of given classifier for given data is plotted\"\"\"\n",
    "    if classifier_name == 'knn':\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "    elif classifier_name == 'svc':\n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = svc_kernel, C = svc_c)\n",
    "    elif classifier_name == 'lr':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression()\n",
    "     \n",
    "    # Fitting classifier to the Training set\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Printing the name of the classifier\n",
    "    print(\"Classificator used:\\n {}\\n\\n\".format(classifier_name))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion matrix: \\n\\n', cm, '\\n\\n')\n",
    "    \n",
    "    # Displaying reports\n",
    "    from sklearn.metrics import classification_report\n",
    "    print('Classification report:\\n\\n', classification_report(y_test, y_pred))\n",
    "    \n",
    "    if visualise:\n",
    "        visualise_classifier(classifier, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
